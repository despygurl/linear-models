{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# 1. Data Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train_sample.csv\")\n",
    "df_test = pd.read_csv(\"test_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600 entries, 0 to 1599\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   sold_date   1136 non-null   object \n",
      " 1   sold_price  1136 non-null   float64\n",
      " 2   year_built  1433 non-null   float64\n",
      " 3   garage      1023 non-null   float64\n",
      " 4   sqft        1150 non-null   float64\n",
      " 5   type        1600 non-null   object \n",
      " 6   price       1594 non-null   float64\n",
      " 7   transport   1600 non-null   bool   \n",
      " 8   services    1600 non-null   int64  \n",
      " 9   beds        1550 non-null   float64\n",
      " 10  floors      1303 non-null   float64\n",
      " 11  baths       1599 non-null   float64\n",
      " 12  lot_sqft    792 non-null    float64\n",
      "dtypes: bool(1), float64(9), int64(1), object(2)\n",
      "memory usage: 151.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   sold_date   279 non-null    object \n",
      " 1   sold_price  279 non-null    float64\n",
      " 2   year_built  357 non-null    float64\n",
      " 3   garage      259 non-null    float64\n",
      " 4   sqft        297 non-null    float64\n",
      " 5   type        400 non-null    object \n",
      " 6   transport   400 non-null    bool   \n",
      " 7   services    400 non-null    int64  \n",
      " 8   beds        390 non-null    float64\n",
      " 9   floors      317 non-null    float64\n",
      " 10  baths       400 non-null    float64\n",
      " 11  lot_sqft    200 non-null    float64\n",
      "dtypes: bool(1), float64(8), int64(1), object(2)\n",
      "memory usage: 34.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# 2. Working with Data. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "### Batasan\n",
    "- **Batas waktu program berjalan**: 10 detik  \n",
    "- **Batas memori**: 128MB  \n",
    "- **Input**: input standar atau `input.txt`  \n",
    "- **Output**: output standar atau `output.txt`  \n",
    "\n",
    "---\n",
    "\n",
    "### Deskripsi\n",
    "\n",
    "Siapkan data untuk pekerjaan selanjutnya dengan model machine learning. Untuk melakukan ini, gunakan metode dari pustaka berikut:\n",
    "\n",
    "- `sklearn.preprocessing.MinMaxScaler`\n",
    "- `sklearn.model_selection.train_test_split`\n",
    "\n",
    "Tulis fungsi bernama:\n",
    "\n",
    "```preprocessing(X: np.ndarray, y: np.ndarray, test_size=0.33)``` \n",
    "\n",
    "dengan parameter input berikut:\n",
    "- `X` : Matriks NumPy berisi fitur objek.\n",
    "- `y`: Vektor NumPy berisi label kebenaran (target).\n",
    "- `test_size`: Menentukan ukuran dataset pengujian sebagai `test_size * 100%` dari total sampel (nilai default dari argumen `test_size` adalah 0.33).\n",
    "\n",
    "Catatan bahwa data harus diacak sebelum dibagi.\n",
    "Gunakan argumen `random_state=1234` pada fungsi `train_test_split` untuk validasi fungsi yang benar.\n",
    "\n",
    "Fungsi ini akan mengembalikan data yang telah diskalakan menggunakan metode `MinMaxScaler`, dan dibagi menjadi dataset pelatihan dan pengujian, di mana panjang dataset pengujian adalah `test_size` dari total sampel. Output harus berupa tuple dengan 4 item:\n",
    "\n",
    "```(X_train: np.ndarray, y_train: np.ndarray, X_test: np.ndarray, y_test: np.ndarray)```\n",
    "\n",
    "> *Pastikan untuk mengikuti urutan operasi yang benar dalam memproses data.*\n",
    "\n",
    "\n",
    "### Contoh\n",
    "#### Input\n",
    "```\n",
    "import numpy as np\n",
    "\n",
    "X, y = np.array([[1, 2], [3, 4], [1, 2]]), np.array([1, 2, 3])\n",
    "X_train, y_train, X_test, y_test = preprocessing(X, y, test_size=0.33)\n",
    "print(X_train, y_train, X_test, y_test, sep='\\n')\n",
    "```\n",
    "\n",
    "#### Output\n",
    "```\n",
    "[[1. 1.]\n",
    " [0. 0.]]\n",
    "[2 3]\n",
    "[[0. 0.]]\n",
    "[1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def preprocessing(X: np.ndarray, y: np.ndarray, test_size=0.33):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=1234\n",
    "    )\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, y_train, X_test_scaled, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns=['price']).to_numpy()\n",
    "y = df_train['price'].to_numpy()\n",
    "\n",
    "# X_train, y_train, X_test, y_test = preprocessing(X, y)\n",
    "# print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Hold-Out Validation\n",
    "**Hold-Out Validation** adalah metode paling dasar dalam evaluasi performa model machine learning. Prinsipnya sederhana: kamu **membagi dataset menjadi dua bagian — satu untuk melatih model (training set)** dan satu lagi untuk **mengujinya (test set)**. Ini memungkinkanmu mengukur seberapa baik model bekerja pada data yang tidak pernah dilihat sebelumnya.\n",
    "\n",
    "Penjelasan langkah-langkahnya:\n",
    "1. Pisahkan data fitur (`X`) dan target (`y`).\n",
    "2. Tentukan ukuran data uji, misalnya `test_size=0.33` berarti 33% dari data total akan jadi test set.\n",
    "3. Acak urutan data agar tidak bias (dalam instruksi ini dengan `np.random.seed(1234)`).\n",
    "4. Bagi data menjadi training dan test set berdasarkan proporsi yang ditentukan.\n",
    "5. Gunakan training set untuk membangun model, dan test set untuk menilai performa.\n",
    "\n",
    "Metode ini cepat, sederhana, dan berguna saat data cukup banyak. Tapi kalau datanya kecil atau ingin validasi lebih stabil, kita bisa menggunakan **k-fold cross-validation**.\n",
    "\n",
    "### Batasan\n",
    "- **Batas waktu program berjalan**: 1 detik  \n",
    "- **Batas memori**: 64MB  \n",
    "- **Input**: input standar atau `input.txt`  \n",
    "- **Output**: output standar atau `output.txt`  \n",
    "\n",
    "---\n",
    "\n",
    "### Deskripsi\n",
    "Lakukan Hold-Out validation dengan meniru perilaku fungsi `train_test_split` dari `sklearn.model_selection`.\n",
    "Kamu tidak boleh menggunakan fungsi bawaan tersebut.\n",
    "\n",
    "Tulis fungsi bernama:\n",
    "\n",
    "```train_test_split(X: np.ndarray, y: np.ndarray, test_size=0.33)``` \n",
    "\n",
    "dengan parameter input berikut:\n",
    "- `X` : Matriks NumPy berisi fitur objek.\n",
    "- `y`: Vektor NumPy berisi label kebenaran (target).\n",
    "- `test_size`: Menentukan ukuran dataset pengujian sebagai `test_size * 100%` dari total sampel (nilai default dari argumen `test_size` adalah 0.33).\n",
    "\n",
    "Fungsi ini harus membagi data menjadi data latih dan data uji, **dengan panjang data uji sebesar `test_size` dari total sampel.**\n",
    "Gunakan fungsi `round()` untuk menghitung jumlah data uji.\n",
    "Output harus berupa **tuple berisi 4 elemen**:\n",
    "\n",
    "```(X_train: np.ndarray, y_train: np.ndarray, X_test: np.ndarray, y_test: np.ndarray)```\n",
    "\n",
    "#### Catatan Penting\n",
    "\n",
    "- Data harus di-*shuffle* (acak) **sebelum dibagi**.\n",
    "- Gunakan nilai seed `1234` untuk `np.random.seed` agar validasi sistem bisa benar.\n",
    "- Hasil pengacakan harus diatur agar data dengan indeks awal (sebanyak `test_size` dari total) masuk ke data uji, dan sisanya ke data latih.\n",
    "- Ini penting agar hasil pembagian *deterministik* dan sesuai sistem pengecekan.\n",
    "\n",
    "\n",
    "### Contoh\n",
    "#### Input\n",
    "```\n",
    "import numpy as np\n",
    "X = np.array([[2, 3], [2, 3], [2, 3]])\n",
    "y = np.array([1, 1, 1])\n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.33)\n",
    "```\n",
    "\n",
    "#### Output\n",
    "```\n",
    "[[2 3]]     ← X_train\n",
    "[1 1]       ← y_train\n",
    "[[2 3]]     ← X_test\n",
    "[1]         ← y_test\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_test_split(X: np.ndarray, y: np.ndarray, test_size=0.33):\n",
    "    np.random.seed(1234)\n",
    "    n_samples = len(X)\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    test_count = round(test_size * n_samples)\n",
    "    test_indices = indices[:test_count]\n",
    "    train_indices = indices[test_count:]\n",
    "\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## OneHot Encoder\n",
    "\n",
    "### Batasan\n",
    "- **Batas waktu program berjalan**: 1 detik  \n",
    "- **Batas memori**: 64MB  \n",
    "- **Input**: input standar atau `input.txt`  \n",
    "- **Output**: output standar atau `output.txt`  \n",
    "\n",
    "---\n",
    "\n",
    "### Deskripsi\n",
    "Implementasikan versi sederhana dari transformasi one_hot_encoding tanpa menggunakan `pd.get_dummies` atau `sklearn.preprocessing.OneHotEncoder`.\n",
    "\n",
    "Tulis fungsi bernama:\n",
    "\n",
    "```def onehot_encoding(X: np.ndarray) -> np.ndarray:``` \n",
    "\n",
    "- Fungsi ini menerima X sebagai input, yaitu array NumPy berdimensi satu yang berisi nilai kategori.\n",
    "- Fungsi harus mengembalikan array NumPy bertipe integer (isi 0 atau 1) dengan ukuran: ```(jumlah data) × (jumlah nilai unik dalam X)``` yang menunjukkan representasi one-hot dari masing-masing elemen dalam X.\n",
    "\n",
    "#### Urutan kolom:\n",
    "\n",
    "- Vektor biner (hasil one-hot) disusun berdasarkan urutan menaik dari nilai kategori.\n",
    "\n",
    "- Contoh: jika nilai unik dalam X adalah b, a, dan c, maka mereka akan diurutkan menjadi a, b, c.\n",
    "\n",
    "- Kolom pertama dalam output mewakili a, kolom kedua b, dan kolom terakhir c.\n",
    "\n",
    "\n",
    "### Contoh\n",
    "#### Input\n",
    "```\n",
    "x = np.array([3, 2, 2, 1])\n",
    "print(onehot_encoding(x))\n",
    "```\n",
    "\n",
    "#### Output\n",
    "```\n",
    "[[0 0 1]\n",
    " [0 1 0]\n",
    " [0 1 0]\n",
    " [1 0 0]]\n",
    "```\n",
    "> Karena nilai unik dalam X adalah `1, 2, 3` (urut menaik), maka:\n",
    "> - \"`1` → [1, 0, 0]\"\n",
    "> - \"`2` → [0, 1, 0]\"\n",
    "> - \"`3` → [0, 0, 1]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def onehot_encoding(X: np.ndarray) -> np.ndarray:\n",
    "    unique_vals = np.sort(np.unique(X))\n",
    "    val_to_index = {val: idx for idx, val in enumerate(unique_vals)}\n",
    "    \n",
    "    onehot = np.zeros((X.shape[0], unique_vals.shape[0]), dtype=int)\n",
    "    for i, val in enumerate(X):\n",
    "        onehot[i, val_to_index[val]] = 1\n",
    "\n",
    "    return onehot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## MinMax Scaler\n",
    "\n",
    "### Batasan\n",
    "- **Batas waktu program berjalan**: 1 detik  \n",
    "- **Batas memori**: 64MB  \n",
    "- **Input**: input standar atau `input.txt`  \n",
    "- **Output**: output standar atau `output.txt`  \n",
    "\n",
    "---\n",
    "\n",
    "### Deskripsi\n",
    "Lakukan transformasi MinMaxScaler yang meniru perilaku dari metode `sklearn.preprocessing.MinMaxScaler`. Kamu **tidak boleh menggunakan** metode bawaan dari pustaka tersebut.\n",
    "\n",
    "Buatlah fungsi `minmax_scale(X: np.ndarray) -> np.ndarray` yang menerima matriks fitur `X` dalam format array NumPy dan mengembalikan matriks yang telah diskalakan menggunakan metode **MinMaxScaler** dalam format array NumPy.\n",
    "\n",
    "**Pastikan kamu juga menangani kasus ketika suatu fitur hanya memiliki satu nilai. Dalam kasus seperti itu, fungsi harus mengembalikan nilai normalisasi paling minimum (yaitu 0).**\n",
    "\n",
    "\n",
    "### Contoh\n",
    "#### Input\n",
    "```\n",
    "import numpy as np\n",
    "X = np.array([[1, 2],\n",
    "              [2, 1]])\n",
    "\n",
    "print(minmax_scale(X))\n",
    "```\n",
    "\n",
    "#### Output\n",
    "```\n",
    "[[0. 1.]\n",
    " [1. 0.]]\n",
    "```\n",
    "\n",
    "### Catatan\n",
    "File yang dikirim ke sistem pengujian hanya boleh berisi fungsi yang diminta dalam soal beserta fungsi pembantu (jika ada). Jangan lupa juga mengimpor pustaka yang digunakan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def minmax_scale(X: np.ndarray) -> np.ndarray:\n",
    "    X_min = X.min(axis=0)\n",
    "    X_max = X.max(axis=0)\n",
    "    denom = X_max - X_min\n",
    "    denom[denom == 0] = 1  # Hindari pembagian dengan nol\n",
    "    return (X - X_min) / denom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:coba_env] *",
   "language": "python",
   "name": "conda-env-coba_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
